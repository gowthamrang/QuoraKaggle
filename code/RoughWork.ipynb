{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter , defaultdict\n",
    "from keras.utils import Sequence\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import Utils\n",
    "from Architecture import lstm_gru_attn\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "FOLDS = 3 #donot change\n",
    "DATA_SPLIT_SEED = 1403 #donot change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')    \n",
    "def getxyfromdf(df, T): return pad_sequences(T.text_to_sequence(df.question_text.values), maxlen=config['seq_len'], padding='post'), df.target.values  if 'target' in df else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')    \n",
    "\n",
    "\n",
    "\n",
    "class Tokenizer():  \n",
    "    def __init__(self, max_vocab=400000):\n",
    "        self.c = Counter()\n",
    "        self.word2id, self.id2word = {\"#pad#\":0}  , ['#pad#']\n",
    "        self.MAX_VOCAB = 400000\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        for each in \"!\\\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'â€™'\":\n",
    "            text = text.replace(each,'')        \n",
    "        return text.split(' ')\n",
    "        \n",
    "    def fit_texts(self,texts, embeddings_index=None):\n",
    "        for text in texts:\n",
    "            self.c.update(self.tokenize(text))   \n",
    "        if embeddings_index !=None: self.build_vocab(embeddings_index)\n",
    "        \n",
    "    def text_to_sequence(self,texts):\n",
    "       return [[ self.word2id[x] if x in self.word2id else 0  for x in self.tokenize(text) ] for text in texts]\n",
    "        \n",
    "    def sequences_to_text(self,seqs):\n",
    "        return [' '.join( self.id2word[i] for x in seq) for seq in seqs]\n",
    "\n",
    "    def build_vocab(self, embedding_index):\n",
    "        if embedding_index:\n",
    "            all_embs = np.stack(embeddings_index.values())\n",
    "            emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "        else:\n",
    "            emb_mean,emb_std = 0., 1.\n",
    "\n",
    "        vocab_size = min(self.MAX_VOCAB, len(self.c))\n",
    "        #self.embedding_matrix = np.random.normal( emb_mean, emb_std, (vocab_size, all_embs.shape[1]))\n",
    "        self.embedding_matrix =  K.eval(tf.truncated_normal((vocab_size, 300), emb_mean, emb_std))\n",
    "        self.unrepresented = []\n",
    "        for ind,word in enumerate(sorted(self.c, key= lambda x: self.c[x], reverse=True)) :\n",
    "            if ind > vocab_size: break\n",
    "\n",
    "            self.word2id[word] = len(self.id2word)\n",
    "            self.id2word.append(word)\n",
    "            if word in embedding_index:\n",
    "                self.embedding_matrix[ind] = embedding_index[word]\n",
    "            elif word.lower() in embedding_index:\n",
    "                self.embedding_matrix[ind] = embedding_index[word.lower()]\n",
    "            else:\n",
    "                self.unrepresented.append(word)\n",
    "        return\n",
    "################################\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        self.b = self.add_weight((input_shape[1],),\n",
    "                                    initializer='zero',\n",
    "                                    name='{}_b'.format(self.name),\n",
    "                                    regularizer=self.b_regularizer,\n",
    "                                    constraint=self.b_constraint) if self.bias else None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None): return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias: eij += self.b\n",
    "        eij = K.tanh(eij)\n",
    "        a = K.exp(eij)\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "####################  \n",
    "def lstm_gru_attn(embedding_matrix):\n",
    "    global config\n",
    "    inp = Input(shape=(config['seq_len'],)) \n",
    "    x = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights = [embedding_matrix], trainable=True)(inp)    \n",
    "    x = SpatialDropout1D(config['dropout'])(x)\n",
    "    x = Bidirectional(CuDNNLSTM(config['internal_dim'], return_sequences=True))(x) \n",
    "    y = Bidirectional(CuDNNGRU(config['internal_dim'], return_sequences=True))(x)\n",
    "    A1 = Attention(config['seq_len'])(x)\n",
    "    A2 = Attention(config['seq_len'])(y)\n",
    "\n",
    "    pool1 = GlobalAveragePooling1D()(y)\n",
    "    pool2 = GlobalMaxPooling1D()(y)\n",
    "    concat = concatenate([pool1, pool2, A1, A2])\n",
    "    x = Dense(64, activation=\"relu\")(concat)\n",
    "    x = Dropout(config['dropout'])(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    opt = Adam(lr=config['lr'], decay=1e-6)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)  \n",
    "    print(model.summary())\n",
    "    return model\n",
    "    \n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_round(model, model_dir, train_x, train_y, val_x, val_y, tx, epochs):\n",
    "    callbacks = [   ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=1, min_lr=0.001),\n",
    "                    ModelCheckpoint(filepath='%s/weights.{epoch:02d}-{val_loss:.3f}.hdf5' %model_dir, monitor='val_loss'),\n",
    "                    Utils.Metrics()]\n",
    "    #model.fit(train_x,train_y,validation_data = (val_x, val_y), batch_size=config['bs'], epochs=epochs, callbacks=callbacks)\n",
    "    print('Averaging predictions...')        \n",
    "    #averaging -outputs\n",
    "    top_k = []\n",
    "    for ck_file in os.listdir(model_dir):\n",
    "        top_k.append((float(ck_file.split('-')[1][:5]), ck_file))\n",
    "    top_k.sort()\n",
    "    val_pred_y = np.zeros_like(val_y, dtype=float)\n",
    "    test_y = np.zeros((tx.shape[0],1))\n",
    "    print(top_k)\n",
    "    CHKPOINTS = len(top_k) if len(top_k) <  config['top_k_checkpoints'] else config['top_k_checkpoints']\n",
    "    for _,model_file in top_k[:config['top_k_checkpoints']]:\n",
    "        model.load_weights(os.path.abspath(f'{model_dir}/{model_file}'))\n",
    "        val_pred_y += model.predict(val_x).reshape(-1)\n",
    "        test_y += model.predict(tx).reshape(-1)\n",
    "    return val_pred_y/CHKPOINTS, test_y/CHKPOINTS\n",
    "\n",
    "\n",
    "##################### HELPER FUNC ENDS ####################\n",
    "def preprocess(train_df, test_df, embeddings_index):\n",
    "    T = Tokenizer()\n",
    "    T.fit_texts(train_df.question_text.values)\n",
    "    T.fit_texts(test_df.question_text.values)\n",
    "    T.build_vocab(embeddings_index)\n",
    "    return T\n",
    "\n",
    "def train_full(train_df, test_df, embeddings_index):\n",
    "    global FOLDS, config\n",
    "    T = preprocess(train_df, test_df, embeddings_index)\n",
    "    train_X, train_Y = getxyfromdf(train_df, T)\n",
    "    test_X, _ = getxyfromdf(test_df, T)      \n",
    "    train_X = train_X[:1000]\n",
    "    train_Y = train_Y[:1000]\n",
    "    test_X = test_X[:1000]\n",
    "    model = config['func'](T.embedding_matrix, **config)\n",
    "    #Utils.search_lr(model,train_X, train_Y)\n",
    "    print('Splitting stratified k fold')\n",
    "    splits = list(StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=DATA_SPLIT_SEED).split(train_X, train_Y))    \n",
    "    \n",
    "    train_meta = np.zeros_like(train_Y)\n",
    "    test_meta = np.zeros((test_X.shape[0],1))\n",
    "    \n",
    "    for idx, (train_idx, valid_idx) in enumerate(splits):\n",
    "        tr_x = train_X[train_idx]\n",
    "        tr_y = train_Y[train_idx]\n",
    "        val_x = train_X[valid_idx]\n",
    "        val_y = train_Y[valid_idx]       \n",
    "        print(f\"Running fold {idx}\") \n",
    "        val_pred_y, test_y = one_round(model,config['model_dir'], tr_x, tr_y, val_x, val_y, test_X, 5)\n",
    "        train_meta[valid_idx] = val_pred_y.reshape(-1)\n",
    "        test_meta += test_y/FOLDS\n",
    "    print('Getting best threshold and saving the test tsv file')\n",
    "    #th = get_best_threshold(val_pred_y, val_y)\n",
    "    train_df[f\"targets_{config['func'].__name__}_avg_{config['top_k_checkpoints']}\"] = train_meta\n",
    "    train_df.to_csv(\"../output/train.csv\", index_label ='qid')\n",
    "\n",
    "    test_df[f\"targets_{config['func'].__name__}_avg_{config['top_k_checkpoints']}\"] = test_meta    \n",
    "    test_df.to_csv(\"../output/test.csv\", index_label ='qid')    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ CONFIGURATIONS #################\n",
    "\n",
    "config = {}\n",
    "config['embedding'] = 'None'\n",
    "config['seq_len'] = 100\n",
    "config['bs'] = 512\n",
    "config['dropout'] = 0.25\n",
    "config['internal_dim'] = 100\n",
    "config['lr'] = 0.01\n",
    "config['func'] = lstm_gru_attn #function is used as a variable\n",
    "config['top_k_checkpoints'] = 3 #for checkpoint ensemble-averaging (maximum of epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../output/train.csv\")\n",
    "test_df = pd.read_csv(\"../output/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = preprocess(train_df, test_df, {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, _ = getxyfromdf(test_df, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   202   1167   1480      6 301786    202   2494   1167   1300    100\n",
      "      3  33116  48108   3237      5     20    807   2494   1480      2\n",
      "      6     20   1167    330      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "print(test_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 300)     92877300    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 100, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 200)     321600      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 100, 200)     181200      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 200)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 200)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 200)          300         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 200)          300         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           51264       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 93,432,029\n",
      "Trainable params: 93,432,029\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = config['func'](T.embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['model_dir'] = '__'.join(f'{k}_{v}' if k != 'func' else f'{k}_{v.__name__}' for k,v in config.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_None__seq_len_100__bs_512__dropout_0.25__internal_dim_100__lr_0.01__func_lstm_gru_attn__top_k_checkpoints_3\n"
     ]
    }
   ],
   "source": [
    "print(config['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1305922/1305922 [==============================] - 282s 216us/step - loss: 0.1458\n",
      "Epoch 0 Aprox. f1 score 0.5128205128205129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[3.8250650e-03],\n",
       "        [4.7505620e-01],\n",
       "        [1.6708693e-02],\n",
       "        [2.4986883e-01],\n",
       "        [6.6158473e-02],\n",
       "        [3.9272744e-02],\n",
       "        [2.2624739e-02],\n",
       "        [2.5330391e-04],\n",
       "        [1.4266948e-01],\n",
       "        [1.2996265e-04],\n",
       "        [5.9139529e-05],\n",
       "        [2.8617883e-03],\n",
       "        [3.2672469e-02],\n",
       "        [4.8926124e-01],\n",
       "        [8.8804518e-05],\n",
       "        [4.9981085e-04],\n",
       "        [1.6471203e-02],\n",
       "        [1.0198958e-01],\n",
       "        [7.0575834e-03],\n",
       "        [1.2649153e-03],\n",
       "        [2.6241252e-03],\n",
       "        [4.1813999e-02],\n",
       "        [4.8926124e-01],\n",
       "        [8.7199820e-04],\n",
       "        [8.5546017e-02],\n",
       "        [8.3202198e-03],\n",
       "        [1.8514927e-04],\n",
       "        [2.7373226e-02],\n",
       "        [1.7099808e-03],\n",
       "        [3.8175346e-04],\n",
       "        [3.5912082e-02],\n",
       "        [3.7833367e-02],\n",
       "        [8.1265735e-04],\n",
       "        [3.4139841e-03],\n",
       "        [3.1649824e-02],\n",
       "        [3.5779181e-01],\n",
       "        [4.2155040e-03],\n",
       "        [4.3278260e-04],\n",
       "        [4.5811966e-02],\n",
       "        [9.8791188e-03],\n",
       "        [3.2010883e-01],\n",
       "        [3.0840063e-02],\n",
       "        [5.9520989e-04],\n",
       "        [2.2423820e-04],\n",
       "        [3.5394775e-04],\n",
       "        [8.6119318e-05],\n",
       "        [1.9396479e-04],\n",
       "        [1.5196371e-03],\n",
       "        [6.0502009e-04],\n",
       "        [1.9373795e-03],\n",
       "        [3.6656204e-01],\n",
       "        [3.3836528e-03],\n",
       "        [5.6408328e-04],\n",
       "        [4.4055749e-03],\n",
       "        [4.3676760e-02],\n",
       "        [2.2627857e-04],\n",
       "        [1.0456047e-01],\n",
       "        [1.2138195e-02],\n",
       "        [2.6271063e-01],\n",
       "        [4.7708567e-02],\n",
       "        [2.5212582e-02],\n",
       "        [3.4482357e-01],\n",
       "        [2.2628738e-03],\n",
       "        [3.9800911e-04],\n",
       "        [1.1639223e-02],\n",
       "        [8.3640978e-02],\n",
       "        [3.3847529e-03],\n",
       "        [3.6796129e-01],\n",
       "        [2.2496545e-04],\n",
       "        [5.5179624e-03],\n",
       "        [9.3296479e-04],\n",
       "        [2.4740712e-04],\n",
       "        [4.0550192e-04],\n",
       "        [4.8926124e-01],\n",
       "        [1.6625712e-02],\n",
       "        [2.0597756e-04],\n",
       "        [3.4973610e-03],\n",
       "        [1.9976234e-03],\n",
       "        [2.8709730e-04],\n",
       "        [7.9678948e-04],\n",
       "        [2.6683006e-01],\n",
       "        [1.1416854e-03],\n",
       "        [3.9854054e-03],\n",
       "        [8.1205234e-02],\n",
       "        [3.5980248e-04],\n",
       "        [2.7480887e-03],\n",
       "        [6.3979661e-04],\n",
       "        [1.8404532e-03],\n",
       "        [6.0010105e-02],\n",
       "        [6.4670166e-05],\n",
       "        [1.2162790e-03],\n",
       "        [5.8682244e-02],\n",
       "        [1.7079538e-02],\n",
       "        [4.8926124e-01],\n",
       "        [3.3175886e-02],\n",
       "        [7.5957907e-04],\n",
       "        [7.5974478e-04],\n",
       "        [9.8210543e-02],\n",
       "        [1.2817730e-03],\n",
       "        [4.6942303e-01],\n",
       "        [3.7433642e-03],\n",
       "        [2.9671719e-02],\n",
       "        [6.5299764e-04],\n",
       "        [3.1040618e-01],\n",
       "        [5.1178213e-02],\n",
       "        [4.1812625e-02],\n",
       "        [1.1673683e-03],\n",
       "        [1.4922339e-03],\n",
       "        [1.1202861e-03],\n",
       "        [4.8926124e-01],\n",
       "        [1.2847675e-03],\n",
       "        [4.1181725e-04],\n",
       "        [3.1126547e-03],\n",
       "        [4.9007172e-04],\n",
       "        [1.7419594e-03],\n",
       "        [1.2730659e-02],\n",
       "        [1.5768777e-04],\n",
       "        [6.2562307e-05],\n",
       "        [4.3241645e-04],\n",
       "        [9.1448732e-05],\n",
       "        [1.1191231e-04],\n",
       "        [3.5092074e-02],\n",
       "        [1.4493918e-01],\n",
       "        [4.0870727e-04],\n",
       "        [2.6973736e-02],\n",
       "        [1.9634708e-03],\n",
       "        [1.0367183e-02],\n",
       "        [2.7758768e-03],\n",
       "        [1.3266398e-01],\n",
       "        [2.2901225e-04],\n",
       "        [1.0479796e-03],\n",
       "        [3.1098224e-02],\n",
       "        [1.2498802e-03],\n",
       "        [3.7305150e-03],\n",
       "        [1.7788763e-01],\n",
       "        [8.4743527e-04],\n",
       "        [9.4161602e-04],\n",
       "        [4.4557578e-03],\n",
       "        [2.9692936e-04],\n",
       "        [4.2848551e-04],\n",
       "        [2.3895884e-01],\n",
       "        [1.3764324e-02],\n",
       "        [2.7578403e-04],\n",
       "        [1.6595536e-01],\n",
       "        [1.2013852e-02],\n",
       "        [2.6182574e-03],\n",
       "        [7.0736220e-04],\n",
       "        [2.3802752e-03],\n",
       "        [1.2161921e-01],\n",
       "        [4.7460902e-01],\n",
       "        [1.8780023e-01],\n",
       "        [5.1719305e-04],\n",
       "        [5.3634485e-03],\n",
       "        [3.8795717e-04],\n",
       "        [6.7857577e-04],\n",
       "        [1.4172029e-03],\n",
       "        [2.5323170e-04],\n",
       "        [4.1104839e-03],\n",
       "        [4.2245103e-04],\n",
       "        [1.4733641e-03],\n",
       "        [1.4239367e-03],\n",
       "        [4.8535722e-03],\n",
       "        [1.1452801e-02],\n",
       "        [3.9254385e-04],\n",
       "        [1.8739884e-03],\n",
       "        [3.2972620e-04],\n",
       "        [4.5029789e-02],\n",
       "        [4.9677789e-03],\n",
       "        [3.5048347e-02],\n",
       "        [2.9459962e-01],\n",
       "        [3.3372840e-01],\n",
       "        [4.8926124e-01],\n",
       "        [4.8926124e-01],\n",
       "        [2.5629488e-04],\n",
       "        [5.7368033e-04],\n",
       "        [2.6481820e-04],\n",
       "        [1.4542937e-02],\n",
       "        [4.8926124e-01],\n",
       "        [3.3628005e-01],\n",
       "        [4.8926124e-01],\n",
       "        [2.2157433e-03],\n",
       "        [4.8926124e-01],\n",
       "        [1.6595917e-04],\n",
       "        [2.0703410e-04],\n",
       "        [2.7625345e-02],\n",
       "        [1.6888496e-04],\n",
       "        [9.4894625e-05],\n",
       "        [1.0980127e-03],\n",
       "        [1.5873725e-03],\n",
       "        [2.1951612e-02],\n",
       "        [4.5178849e-01],\n",
       "        [1.4519913e-04],\n",
       "        [3.6000769e-04],\n",
       "        [2.4059517e-04],\n",
       "        [6.7305831e-05],\n",
       "        [6.0738104e-05],\n",
       "        [6.8688509e-03],\n",
       "        [1.1302393e-03],\n",
       "        [1.3196481e-04],\n",
       "        [5.2349665e-04]], dtype=float32), array([[3.8250650e-03],\n",
       "        [4.7505620e-01],\n",
       "        [1.6708693e-02],\n",
       "        [2.4986883e-01],\n",
       "        [6.6158473e-02],\n",
       "        [3.9272744e-02],\n",
       "        [2.2624739e-02],\n",
       "        [2.5330391e-04],\n",
       "        [1.4266948e-01],\n",
       "        [1.2996265e-04],\n",
       "        [5.9139529e-05],\n",
       "        [2.8617883e-03],\n",
       "        [3.2672469e-02],\n",
       "        [4.8926124e-01],\n",
       "        [8.8804518e-05],\n",
       "        [4.9981085e-04],\n",
       "        [1.6471203e-02],\n",
       "        [1.0198958e-01],\n",
       "        [7.0575834e-03],\n",
       "        [1.2649153e-03],\n",
       "        [2.6241252e-03],\n",
       "        [4.1813999e-02],\n",
       "        [4.8926124e-01],\n",
       "        [8.7199820e-04],\n",
       "        [8.5546017e-02],\n",
       "        [8.3202198e-03],\n",
       "        [1.8514927e-04],\n",
       "        [2.7373226e-02],\n",
       "        [1.7099808e-03],\n",
       "        [3.8175346e-04],\n",
       "        [3.5912082e-02],\n",
       "        [3.7833367e-02],\n",
       "        [8.1265735e-04],\n",
       "        [3.4139841e-03],\n",
       "        [3.1649824e-02],\n",
       "        [3.5779181e-01],\n",
       "        [4.2155040e-03],\n",
       "        [4.3278260e-04],\n",
       "        [4.5811966e-02],\n",
       "        [9.8791188e-03],\n",
       "        [3.2010883e-01],\n",
       "        [3.0840063e-02],\n",
       "        [5.9520989e-04],\n",
       "        [2.2423820e-04],\n",
       "        [3.5394775e-04],\n",
       "        [8.6119318e-05],\n",
       "        [1.9396479e-04],\n",
       "        [1.5196371e-03],\n",
       "        [6.0502009e-04],\n",
       "        [1.9373795e-03],\n",
       "        [3.6656204e-01],\n",
       "        [3.3836528e-03],\n",
       "        [5.6408328e-04],\n",
       "        [4.4055749e-03],\n",
       "        [4.3676760e-02],\n",
       "        [2.2627857e-04],\n",
       "        [1.0456047e-01],\n",
       "        [1.2138195e-02],\n",
       "        [2.6271063e-01],\n",
       "        [4.7708567e-02],\n",
       "        [2.5212582e-02],\n",
       "        [3.4482357e-01],\n",
       "        [2.2628738e-03],\n",
       "        [3.9800911e-04],\n",
       "        [1.1639223e-02],\n",
       "        [8.3640978e-02],\n",
       "        [3.3847529e-03],\n",
       "        [3.6796129e-01],\n",
       "        [2.2496545e-04],\n",
       "        [5.5179624e-03],\n",
       "        [9.3296479e-04],\n",
       "        [2.4740712e-04],\n",
       "        [4.0550192e-04],\n",
       "        [4.8926124e-01],\n",
       "        [1.6625712e-02],\n",
       "        [2.0597756e-04],\n",
       "        [3.4973610e-03],\n",
       "        [1.9976234e-03],\n",
       "        [2.8709730e-04],\n",
       "        [7.9678948e-04],\n",
       "        [2.6683006e-01],\n",
       "        [1.1416854e-03],\n",
       "        [3.9854054e-03],\n",
       "        [8.1205234e-02],\n",
       "        [3.5980248e-04],\n",
       "        [2.7480887e-03],\n",
       "        [6.3979661e-04],\n",
       "        [1.8404532e-03],\n",
       "        [6.0010105e-02],\n",
       "        [6.4670166e-05],\n",
       "        [1.2162790e-03],\n",
       "        [5.8682244e-02],\n",
       "        [1.7079538e-02],\n",
       "        [4.8926124e-01],\n",
       "        [3.3175886e-02],\n",
       "        [7.5957907e-04],\n",
       "        [7.5974478e-04],\n",
       "        [9.8210543e-02],\n",
       "        [1.2817730e-03],\n",
       "        [4.6942303e-01],\n",
       "        [3.7433642e-03],\n",
       "        [2.9671719e-02],\n",
       "        [6.5299764e-04],\n",
       "        [3.1040618e-01],\n",
       "        [5.1178213e-02],\n",
       "        [4.1812625e-02],\n",
       "        [1.1673683e-03],\n",
       "        [1.4922339e-03],\n",
       "        [1.1202861e-03],\n",
       "        [4.8926124e-01],\n",
       "        [1.2847675e-03],\n",
       "        [4.1181725e-04],\n",
       "        [3.1126547e-03],\n",
       "        [4.9007172e-04],\n",
       "        [1.7419594e-03],\n",
       "        [1.2730659e-02],\n",
       "        [1.5768777e-04],\n",
       "        [6.2562307e-05],\n",
       "        [4.3241645e-04],\n",
       "        [9.1448732e-05],\n",
       "        [1.1191231e-04],\n",
       "        [3.5092074e-02],\n",
       "        [1.4493918e-01],\n",
       "        [4.0870727e-04],\n",
       "        [2.6973736e-02],\n",
       "        [1.9634708e-03],\n",
       "        [1.0367183e-02],\n",
       "        [2.7758768e-03],\n",
       "        [1.3266398e-01],\n",
       "        [2.2901225e-04],\n",
       "        [1.0479796e-03],\n",
       "        [3.1098224e-02],\n",
       "        [1.2498802e-03],\n",
       "        [3.7305150e-03],\n",
       "        [1.7788763e-01],\n",
       "        [8.4743527e-04],\n",
       "        [9.4161602e-04],\n",
       "        [4.4557578e-03],\n",
       "        [2.9692936e-04],\n",
       "        [4.2848551e-04],\n",
       "        [2.3895884e-01],\n",
       "        [1.3764324e-02],\n",
       "        [2.7578403e-04],\n",
       "        [1.6595536e-01],\n",
       "        [1.2013852e-02],\n",
       "        [2.6182574e-03],\n",
       "        [7.0736220e-04],\n",
       "        [2.3802752e-03],\n",
       "        [1.2161921e-01],\n",
       "        [4.7460902e-01],\n",
       "        [1.8780023e-01],\n",
       "        [5.1719305e-04],\n",
       "        [5.3634485e-03],\n",
       "        [3.8795717e-04],\n",
       "        [6.7857577e-04],\n",
       "        [1.4172029e-03],\n",
       "        [2.5323170e-04],\n",
       "        [4.1104839e-03],\n",
       "        [4.2245103e-04],\n",
       "        [1.4733641e-03],\n",
       "        [1.4239367e-03],\n",
       "        [4.8535722e-03],\n",
       "        [1.1452801e-02],\n",
       "        [3.9254385e-04],\n",
       "        [1.8739884e-03],\n",
       "        [3.2972620e-04],\n",
       "        [4.5029789e-02],\n",
       "        [4.9677789e-03],\n",
       "        [3.5048347e-02],\n",
       "        [2.9459962e-01],\n",
       "        [3.3372840e-01],\n",
       "        [4.8926124e-01],\n",
       "        [4.8926124e-01],\n",
       "        [2.5629488e-04],\n",
       "        [5.7368033e-04],\n",
       "        [2.6481820e-04],\n",
       "        [1.4542937e-02],\n",
       "        [4.8926124e-01],\n",
       "        [3.3628005e-01],\n",
       "        [4.8926124e-01],\n",
       "        [2.2157433e-03],\n",
       "        [4.8926124e-01],\n",
       "        [1.6595917e-04],\n",
       "        [2.0703410e-04],\n",
       "        [2.7625345e-02],\n",
       "        [1.6888496e-04],\n",
       "        [9.4894625e-05],\n",
       "        [1.0980127e-03],\n",
       "        [1.5873725e-03],\n",
       "        [2.1951612e-02],\n",
       "        [4.5178849e-01],\n",
       "        [1.4519913e-04],\n",
       "        [3.6000769e-04],\n",
       "        [2.4059517e-04],\n",
       "        [6.7305831e-05],\n",
       "        [6.0738104e-05],\n",
       "        [6.8688509e-03],\n",
       "        [1.1302393e-03],\n",
       "        [1.3196481e-04],\n",
       "        [5.2349665e-04]], dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['bs'] = 512\n",
    "def one_round(model, train_x, train_y, val_x, val_y, tx, epochs ):\n",
    "    for e in range(epochs):\n",
    "        model.fit(train_x,train_y,batch_size=config['bs'],epochs=1)\n",
    "        val_pred_y = model.predict(val_x)\n",
    "        print(f\"Epoch {e} Aprox. f1 score {f1_score(val_y, (val_pred_y>0.33).astype(int))}\")\n",
    "    test_y = model.predict(tx)\n",
    "    return val_pred_y, test_y\n",
    "\n",
    "one_round(model, train_X[:-200], train_Y[:-200], train_X[-200:], train_Y[-200:],train_X[-200:], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "d = np.expand_dims(model.predict(test_X[:100]).reshape(-1), -1)\n",
    "print(d.shape)\n",
    "a = np.zeros((100,1))\n",
    "a+=d\n",
    "print(a.shape)\n",
    "a+=d\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48444149]\n",
      " [0.49389109]\n",
      " [0.48593161]\n",
      " [0.48696923]\n",
      " [0.4991526 ]\n",
      " [0.49707583]\n",
      " [0.52118498]\n",
      " [0.48951164]\n",
      " [0.50385362]\n",
      " [0.51378775]\n",
      " [0.5108884 ]\n",
      " [0.51923281]\n",
      " [0.51136273]\n",
      " [0.50487673]\n",
      " [0.50920314]\n",
      " [0.51349086]\n",
      " [0.49687502]\n",
      " [0.49227223]\n",
      " [0.51492447]\n",
      " [0.52305216]\n",
      " [0.48883221]\n",
      " [0.50302064]\n",
      " [0.49143434]\n",
      " [0.48148397]\n",
      " [0.48970875]\n",
      " [0.49274215]\n",
      " [0.50405902]\n",
      " [0.49849731]\n",
      " [0.48860711]\n",
      " [0.51239836]\n",
      " [0.5018838 ]\n",
      " [0.49873376]\n",
      " [0.50038904]\n",
      " [0.50494868]\n",
      " [0.49185887]\n",
      " [0.49737763]\n",
      " [0.48988467]\n",
      " [0.48634624]\n",
      " [0.48796317]\n",
      " [0.48749572]\n",
      " [0.49894869]\n",
      " [0.48984325]\n",
      " [0.49809527]\n",
      " [0.48978749]\n",
      " [0.49380562]\n",
      " [0.51031619]\n",
      " [0.47291368]\n",
      " [0.49224287]\n",
      " [0.48953071]\n",
      " [0.49444014]\n",
      " [0.50728899]\n",
      " [0.4991591 ]\n",
      " [0.49828416]\n",
      " [0.48398679]\n",
      " [0.48954305]\n",
      " [0.50335997]\n",
      " [0.49956635]\n",
      " [0.49433103]\n",
      " [0.4820722 ]\n",
      " [0.47481823]\n",
      " [0.49451485]\n",
      " [0.51256329]\n",
      " [0.47891903]\n",
      " [0.47831735]\n",
      " [0.50247973]\n",
      " [0.50335586]\n",
      " [0.48612651]\n",
      " [0.50956249]\n",
      " [0.47454956]\n",
      " [0.50688696]\n",
      " [0.49787948]\n",
      " [0.50249481]\n",
      " [0.49506259]\n",
      " [0.50030541]\n",
      " [0.49332774]\n",
      " [0.49358562]\n",
      " [0.49444813]\n",
      " [0.46991169]\n",
      " [0.50937068]\n",
      " [0.48493144]\n",
      " [0.52129215]\n",
      " [0.49772006]\n",
      " [0.49225551]\n",
      " [0.50923139]\n",
      " [0.50565237]\n",
      " [0.49698848]\n",
      " [0.47456977]\n",
      " [0.49968621]\n",
      " [0.47484317]\n",
      " [0.48357934]\n",
      " [0.50544286]\n",
      " [0.49273568]\n",
      " [0.50130916]\n",
      " [0.50432038]\n",
      " [0.48975375]\n",
      " [0.48247859]\n",
      " [0.50438112]\n",
      " [0.47937542]\n",
      " [0.48091534]\n",
      " [0.50086099]]\n"
     ]
    }
   ],
   "source": [
    "print(a/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
